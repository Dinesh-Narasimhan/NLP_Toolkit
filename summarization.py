# -*- coding: utf-8 -*-
"""summarization.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JWd0tuOk4HYETEeB6BaIp0skLtF7lLys
"""

from transformers import pipeline

# Load summarization pipeline with a longer max token limit
summarizer = pipeline("summarization", model="facebook/bart-large-cnn")

def summarize_text(text):
    # Break text into chunks if needed (BART handles ~1024 tokens max)
    max_chunk = 800
    text = text.strip().replace("\n", " ")
    sentences = text.split('. ')
    current_chunk = ''
    chunks = []

    for sentence in sentences:
        if len(current_chunk) + len(sentence.split(' ')) <= max_chunk:
            current_chunk += sentence + '. '
        else:
            chunks.append(current_chunk.strip())
            current_chunk = sentence + '. '
    chunks.append(current_chunk.strip())

    # Summarize each chunk
    summary = []
    for chunk in chunks:
        part = summarizer(chunk, max_length=180, min_length=60, do_sample=False)
        summary.append(part[0]['summary_text'])

    return ' '.join(summary)

